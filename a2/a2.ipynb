{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors   \n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from math import log\n",
    "from math import sqrt\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeans(X,Y) : \n",
    "    mu_set = []\n",
    "    for i in range(3) : \n",
    "        mu_set.append(np.array([np.mean(X[i]), np.mean(Y[i])]))\n",
    "    return mu_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1(X,Y,X_total,Y_total) : \n",
    "    mu_set = getMeans(X,Y)\n",
    "\n",
    "    #covariance matrix\n",
    "    sigma = np.zeros(shape=(2,2))\n",
    "    sum = 0\n",
    "    for i in range(3) : \n",
    "        n = X[i].shape[0]\n",
    "        sigma += (n-1) * np.cov(np.array([X[i],Y[i]]))\n",
    "        sum += n\n",
    "    sigma_set = [sigma/(sum-3)] * 3\n",
    "\n",
    "    # plot_set1(X_total,Y_total,mu_set,sigma_set)\n",
    "    return sigma_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(X,Y,X_total,Y_total) :\n",
    "    mu_set = getMeans(X,Y)\n",
    "\n",
    "    #covariance matrix\n",
    "    sigma_set = []\n",
    "    for i in range(3) : \n",
    "        n = X[i].shape[0]\n",
    "        sigma = np.cov(np.array([X[i],Y[i]]))\n",
    "        sigma_set.append(sigma)\n",
    "\n",
    "    # plot_set1(X_total,Y_total,mu_set,sigma_set)\n",
    "    return sigma_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train3(X,Y,X_total,Y_total) : \n",
    "    mu_set = getMeans(X,Y)\n",
    "    \n",
    "    #covariance value\n",
    "    n = 0 \n",
    "    sigma = 0.0\n",
    "    for i in range(3) : \n",
    "        m = X[i].shape[0]\n",
    "        n += m*2\n",
    "        for j in range(m) : \n",
    "            sigma += (X[i][j] - mu_set[i][0])**2 + (Y[i][j] - mu_set[i][1])**2\n",
    "    temp_array = np.array([[sigma/(n-6),0],[0,sigma/(n-6)]])\n",
    "    sigma_set = [temp_array] * 3\n",
    "\n",
    "    # plot_set1(X_total,Y_total,mu_set,sigma_set)\n",
    "    return sigma_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train4(X,Y,X_total,Y_total) : \n",
    "    mu_set = getMeans(X,Y)\n",
    "\n",
    "    n = 0\n",
    "    sigma1 = 0.0\n",
    "    sigma2 = 0.0\n",
    "    for i in range(3) :\n",
    "        m = X[i].shape[0]\n",
    "        n += m\n",
    "        for j in range(m) : \n",
    "            sigma1 += (X[i][j] - mu_set[i][0])**2\n",
    "            sigma2 += (Y[i][j] - mu_set[i][1])**2\n",
    "    temp_array = np.array([[sigma1/(n-3),0],[0,sigma2/(n-3)]])\n",
    "    sigma_set = [temp_array] * 3\n",
    "\n",
    "    # plot_set1(X_total,Y_total,mu_set,sigma_set)\n",
    "    return sigma_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train5(X,Y,X_total,Y_total) : \n",
    "    mu_set = getMeans(X,Y)\n",
    "\n",
    "    sigma_set = []\n",
    "    for i in range(3) : \n",
    "        m = X[i].shape[0]\n",
    "        sigma1 = 0.0\n",
    "        sigma2 = 0.0\n",
    "        for j in range(m) : \n",
    "            sigma1 += (X[i][j] - mu_set[i][0])**2\n",
    "            sigma2 += (Y[i][j] - mu_set[i][1])**2\n",
    "        temp_array = np.array([[sigma1/(m-1),0],[0,sigma2/(m-1)]])\n",
    "        sigma_set.append(temp_array)\n",
    "    \n",
    "    # plot_set1(X_total,Y_total,mu_set,sigma_set)\n",
    "    return sigma_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_set1(X_total, Y_total, mu_set, sigma_set) :\n",
    "    x_min = min(X_total)\n",
    "    x_max = max(X_total)\n",
    "    y_min = min(Y_total)\n",
    "    y_max = max(Y_total)\n",
    "\n",
    "    # temp1 = np.arange(x_min,x_max,0.1)\n",
    "    # temp2 = np.arange(y_min,y_max,0.1)\n",
    "    \n",
    "    # for real data, gaps are taken as 1 instead of 0.1 due to the large range\n",
    "    temp1 = np.arange(x_min,x_max,1)\n",
    "    temp2 = np.arange(y_min,y_max,1)\n",
    "\n",
    "    x,y = np.meshgrid(temp1,temp2)\n",
    "    pos = np.empty(x.shape + (2,))\n",
    "    pos[:,:,0] = x\n",
    "    pos[:,:,1] = y\n",
    "\n",
    "    Z = []\n",
    "\n",
    "    for i in range(3) : \n",
    "        sigma_det = np.linalg.det(sigma_set[i])\n",
    "        sigma_inv = np.linalg.inv(sigma_set[i])\n",
    "        N = np.sqrt((2*np.pi)**2 * sigma_det)\n",
    "        fac = np.einsum(\"...k,kl,...l->...\", pos-mu_set[i], sigma_inv, pos-mu_set[i])\n",
    "        Z.append(np.exp(-fac/2)/N)\n",
    "\n",
    "    pdf = np.maximum(np.maximum(Z[0],Z[1]),Z[2])\n",
    "    \n",
    "    plotPDF_Helper(x,y,pdf)\n",
    "    plotContour_Helper(x,y,pdf,x_min,x_max,y_min,y_max)\n",
    "    # plotDecision_helper(x,y,mu_set,sigma_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPDF_Helper(x, y, pdf) : \n",
    "    fig = plt.figure(figsize=(14,9))\n",
    "    ax1 = plt.axes(projection=\"3d\")\n",
    "    ax1.set_xlabel(\"X\")\n",
    "    ax1.set_ylabel(\"Y\")\n",
    "\n",
    "    ax1.plot_surface(x, y, pdf, rstride=3, cstride=3, linewidth=1, antialiased=True, cmap=cm.viridis)\n",
    "    ax1.view_init(20, 30)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotContour_Helper(x, y, pdf, x_min, x_max, y_min, y_max) : \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.gca()\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    cfset = ax.contourf(x, y, pdf, cmap=\"coolwarm\")\n",
    "    ax.imshow(np.rot90(pdf), cmap=\"coolwarm\", extent=[x_min, x_max, y_min, y_max])\n",
    "    cset = ax.contour(x, y, pdf, colors='k')\n",
    "    ax.clabel(cset, inline=1, fontsize=10)\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    plt.title(\"2D Gaussian Kernel density estimation\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier1(point,mu_set,sigma_set) :\n",
    "    sigma = sigma_set[0] \n",
    "    values = []\n",
    "    scores = []\n",
    "    for i in range(3) : \n",
    "        v1 = 2 * point.T @ np.linalg.inv(sigma) @ mu_set[i] \n",
    "        v2 = mu_set[i].T @ np.linalg.inv(sigma) @ mu_set[i]\n",
    "        values.append((v1-v2,i+1))\n",
    "        scores.append(v1-v2)\n",
    "    return (max(values)[1],scores)\n",
    "\n",
    "def classifier2(point,mu_set,sigma_set) : \n",
    "    values = []\n",
    "    scores = []\n",
    "    for i in range(3) : \n",
    "        v1 = log(np.linalg.det(sigma_set[i])) \n",
    "        v2 = (point - mu_set[i]).reshape(2,1).T @ np.linalg.inv(sigma_set[i]) @ (point - mu_set[i]).reshape(2,1)\n",
    "        values.append((-(v1+v2),i+1))\n",
    "        scores.append(-(v1+v2))\n",
    "    return (max(values)[1],scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes classifier \n",
    "# C = sigma^2 I\n",
    "def classifier3(point,mu_set,sigma_set) :\n",
    "    values = []\n",
    "    scores = []\n",
    "    for i in range(3) : \n",
    "        v1 = (point[0] - mu_set[i][0])**2\n",
    "        v2 = (point[1] - mu_set[i][1])**2\n",
    "        values.append((-(v1+v2),i+1))\n",
    "        scores.append(-(v1+v2))\n",
    "    return (max(values)[1],scores)\n",
    "\n",
    "# C1 = C2\n",
    "def classifier4(point,mu_set,sigma_set) :\n",
    "    values = []\n",
    "    scores = []\n",
    "    sigma1 = sigma_set[0][0][0]\n",
    "    sigma2 = sigma_set[0][1][1]\n",
    "    for i in range(3) : \n",
    "        v1 = log(sqrt(sigma1)) + ((point[0] - mu_set[i][0])**2)/(2 * sigma1**2)\n",
    "        v2 = log(sqrt(sigma2)) + ((point[1] - mu_set[i][1])**2)/(2 * sigma2**2)\n",
    "        values.append((-(v1+v2),i+1))\n",
    "        scores.append(-(v1+v2))\n",
    "    return (max(values)[1],scores)\n",
    "\n",
    "# C1 != C2\n",
    "def classifier5(point,mu_set,sigma_set) :\n",
    "    values = []\n",
    "    scores = []\n",
    "    for i in range(3) : \n",
    "        sigma1 = sigma_set[i][0][0]\n",
    "        sigma2 = sigma_set[i][1][1]\n",
    "        v1 = log(sqrt(sigma1)) + ((point[0] - mu_set[i][0])**2)/(2 * sigma1)\n",
    "        v2 = log(sqrt(sigma2)) + ((point[1] - mu_set[i][1])**2)/(2 * sigma2)\n",
    "        values.append((-(v1+v2),i+1))\n",
    "        scores.append(-(v1+v2))\n",
    "    return (max(values)[1],scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(mu_set,sigma_sets,points,class_test_set) :\n",
    "    class_pred_sets = [[],[],[],[],[]]\n",
    "    class_scores = [[],[],[],[],[]]\n",
    "    x_max = max(points[:,0])\n",
    "    x_min = min(points[:,0])\n",
    "    y_max = max(points[:,1])\n",
    "    y_min = min(points[:,1])\n",
    "\n",
    "    # temp1 = np.arange(x_min,x_max,0.1)\n",
    "    # temp2 = np.arange(y_min,y_max,0.1)\n",
    "    \n",
    "    # for real data, gaps are taken as 1 instead of 0.1 due to the large range\n",
    "    temp1 = np.arange(x_min,x_max,1)\n",
    "    temp2 = np.arange(y_min,y_max,1)\n",
    "    \n",
    "    x,y = np.meshgrid(temp1,temp2)\n",
    "\n",
    "    for point in points : \n",
    "        class_pred1,class_scores1 = classifier1(point,mu_set,sigma_sets[0])\n",
    "        class_pred_sets[0].append(class_pred1)\n",
    "        class_scores[0].append(class_scores1)\n",
    "\n",
    "        class_pred2,class_scores2 = classifier2(point,mu_set,sigma_sets[1])\n",
    "        class_pred_sets[1].append(class_pred2)\n",
    "        class_scores[1].append(class_scores2)\n",
    "\n",
    "        class_pred3,class_scores3 = classifier3(point,mu_set,sigma_sets[2])\n",
    "        class_pred_sets[2].append(class_pred3)\n",
    "        class_scores[2].append(class_scores3)\n",
    "\n",
    "        class_pred4,class_scores4 = classifier4(point,mu_set,sigma_sets[3])\n",
    "        class_pred_sets[3].append(class_pred4)\n",
    "        class_scores[3].append(class_scores4)\n",
    "\n",
    "        class_pred5,class_scores5 = classifier5(point,mu_set,sigma_sets[4])\n",
    "        class_pred_sets[4].append(class_pred5)\n",
    "        class_scores[4].append(class_scores5)\n",
    "\n",
    "    plot_set2(class_scores,class_test_set,class_pred_sets,x,y,mu_set,sigma_sets)\n",
    "    # plotROC(class_scores,class_test_set)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_set2(class_scores,class_test_set,class_pred_sets,x,y,mu_set,sigma_sets) : \n",
    "    # for i in range(5) : \n",
    "    #     plotDecision_helper(x,y,mu_set,sigma_sets[i],i)\n",
    "    \n",
    "    for i in range(5) : \n",
    "        plotConfusionMatrix(class_test_set,class_pred_sets[i])\n",
    "\n",
    "    # plotROC(class_scores,class_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDecision_helper(x,y,mu_set,sigma_set,case) :\n",
    "    x_temp = x.ravel()\n",
    "    y_temp = y.ravel()\n",
    "    z_temp = []\n",
    "    for i in range(x_temp.shape[0]) : \n",
    "        point = np.array([x_temp[i],y_temp[i]]) \n",
    "        if(case == 0) :\n",
    "            z_temp.append(classifier1(point,mu_set,sigma_set)[0])\n",
    "        if(case == 1) :\n",
    "            z_temp.append(classifier2(point,mu_set,sigma_set)[0])\n",
    "        if(case == 2) :\n",
    "            z_temp.append(classifier3(point,mu_set,sigma_set)[0])\n",
    "        if(case == 3) :\n",
    "            z_temp.append(classifier4(point,mu_set,sigma_set)[0])\n",
    "        if(case == 4) :\n",
    "            z_temp.append(classifier5(point,mu_set,sigma_set)[0])\n",
    "    z_temp = np.array(z_temp)\n",
    "    z = z_temp.reshape(x.shape)\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.contourf(x, y, z, cmap=colors.ListedColormap([\"red\",\"green\",\"blue\"]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotConfusionMatrix(class_test_set,class_pred_set) : \n",
    "    class_test_set = np.array(class_test_set)\n",
    "    class_pred_set = np.array(class_pred_set)\n",
    "    fig,ax = plt.subplots(1)\n",
    "    columns = [\"class %s\" %(i) for i in range(1,4)]\n",
    "    confusionMatrix = confusion_matrix(class_test_set,class_pred_set)\n",
    "    df_cm = DataFrame(confusionMatrix, index=columns, columns=columns)\n",
    "    ax = sn.heatmap(df_cm, cmap='Oranges', annot=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotROC(total_scores,class_test_set) : \n",
    "    fig,axarr = plt.subplots(2,figsize=(8,10))\n",
    "    for k in range(5) : \n",
    "        class_scores = []\n",
    "        temp = []\n",
    "        scores = total_scores[k]\n",
    "        for i in range(len(scores)) : \n",
    "            for j in range(3) : \n",
    "                class_scores.append((scores[i][j],class_test_set[i],j+1))\n",
    "                temp.append(scores[i][j])\n",
    "        class_scores = sorted(class_scores)\n",
    "        TPR = []  # TP/(TP+FN)\n",
    "        FNR = []  # FN/(FN+TP)\n",
    "        FPR = []  # FP/(FP+TN)\n",
    "        for threshold in sorted(temp) :  \n",
    "            tp = 0\n",
    "            tn = 0\n",
    "            fp = 0\n",
    "            fn = 0\n",
    "            for data in class_scores : \n",
    "                if(data[0] >= threshold) : \n",
    "                    if(data[1] == data[2]) : \n",
    "                        tp += 1\n",
    "                    else : \n",
    "                        fp += 1\n",
    "                else : \n",
    "                    if(data[1] == data[2]) : \n",
    "                        fn += 1\n",
    "                    else :\n",
    "                        tn += 1\n",
    "            TPR.append(float(tp/(tp+fn)))\n",
    "            FNR.append(float(fn/(fn+tp)))\n",
    "            FPR.append(float(fp/(fp+tn)))\n",
    "    #     plt.subplot(1,2,1)\n",
    "    #     plt.plot(FPR,TPR, label=f\"case-{k+1}\")\n",
    "    #     plt.legend()\n",
    "    #     plt.subplot(1,2,2,figsize=(10,10))\n",
    "    #     plt.plot(FPR,FNR, label=f\"case-{k+1}\")\n",
    "    #     plt.legend()\n",
    "        axarr[0].plot(FPR,TPR,label=f\"case-{k+1}\")\n",
    "        axarr[0].legend()\n",
    "        axarr[1].plot(FPR,FNR,label=f\"case-{k+1}\")\n",
    "        axarr[1].legend()\n",
    "    fig.show()\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayerClassification(train,dev) :\n",
    "    file1 = open(train,\"r\")\n",
    "    X_temp = [[],[],[]]\n",
    "    Y_temp = [[],[],[]]\n",
    "    X_total = []\n",
    "    Y_total = []\n",
    "    for string in file1 : \n",
    "        temp = string.strip().split(\",\")\n",
    "        ind = int(temp[2])-1\n",
    "        X_total.append(float(temp[0]))\n",
    "        Y_total.append(float(temp[1]))\n",
    "        X_temp[ind].append(float(temp[0]))\n",
    "        Y_temp[ind].append(float(temp[1])) \n",
    "    file1.close()\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    X_total = np.array(X_total)\n",
    "    Y_total = np.array(Y_total)\n",
    "    for i in range(3) : \n",
    "        X.append(np.array(X_temp[i]))\n",
    "        Y.append(np.array(Y_temp[i]))\n",
    "    \n",
    "    ############\n",
    "    # temp_array1 = np.array([X_total,Y_total]).T\n",
    "    # temp_array2 = [1]*350 + [2]*350 + [3]*350\n",
    "    # lda = LinearDiscriminantAnalysis()\n",
    "    # lda.fit(temp_array1,temp_array2)\n",
    "    # gnb = GaussianNB()\n",
    "    # gnb.fit(temp_array1,temp_array2)\n",
    "    ############\n",
    "\n",
    "    sigma_sets = []\n",
    "    sigma_sets.append(train1(X,Y,X_total,Y_total))\n",
    "    sigma_sets.append(train2(X,Y,X_total,Y_total))\n",
    "    sigma_sets.append(train3(X,Y,X_total,Y_total))\n",
    "    sigma_sets.append(train4(X,Y,X_total,Y_total))\n",
    "    sigma_sets.append(train5(X,Y,X_total,Y_total))\n",
    "    \n",
    "    mu_set = getMeans(X,Y)\n",
    "    \n",
    "    total = 0\n",
    "    true = 0 \n",
    "    class_test_set = []\n",
    "    points = []\n",
    "    # class_pred_set = []\n",
    "    # scores = []\n",
    "    file2 = open(dev,\"r\")\n",
    "    for string in file2 : \n",
    "        temp = string.strip().split(\",\")\n",
    "        point = np.array([float(temp[0]),float(temp[1])])\n",
    "        # points.append(point)\n",
    "        class_test = int(temp[2])\n",
    "        # class_test_set.append(class_test)\n",
    "        class_pred,class_scores = classifier5(point,mu_set,sigma_sets[4])\n",
    "        # scores.append(class_scores)\n",
    "        # class_pred_set.append(class_pred)\n",
    "        if(class_test == class_pred) :\n",
    "            true += 1\n",
    "        total += 1 \n",
    "    file2.close()\n",
    "    print(f\"accuracy : {100*true/total}%\")\n",
    "    # points = np.array(points)\n",
    "    # classify(mu_set,sigma_sets,points,class_test_set)\n",
    "    # plotConfusionMatrix(np.array(class_test_set),np.array(class_pred_set))\n",
    "    # plotROC(scores,class_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 81.0%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" : \n",
    "    bayerClassification(\"train3.txt\",\"dev3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a27c4395af31c56a434036e1b622de6d5a8cba9d2996ba0d5cc45a2e6e7be025"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
